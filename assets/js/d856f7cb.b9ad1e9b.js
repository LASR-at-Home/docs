"use strict";(self.webpackChunkweb=self.webpackChunkweb||[]).push([[952],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>k});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),u=p(a),d=r,k=u["".concat(s,".").concat(d)]||u[d]||m[d]||l;return a?n.createElement(k,o(o({ref:t},c),{},{components:a})):n.createElement(k,o({ref:t},c))}));function k(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,o=new Array(l);o[0]=d;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[u]="string"==typeof e?e:r,o[1]=i;for(var p=2;p<l;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},4060:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>p});var n=a(7462),r=(a(7294),a(3905));const l={},o="lasr_vision_yolov8",i={unversionedId:"packages/lasr_vision_yolov8",id:"packages/lasr_vision_yolov8",title:"lasr_vision_yolov8",description:"YOLOv8 object detection service",source:"@site/docs/packages/lasr_vision_yolov8.md",sourceDirName:"packages",slug:"/packages/lasr_vision_yolov8",permalink:"/docs/packages/lasr_vision_yolov8",draft:!1,editUrl:"https://github.com/lasr-at-home/base/blob/main/common/document_lasr/web/docs/packages/lasr_vision_yolov8.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"lasr_vision_msgs",permalink:"/docs/packages/lasr_vision_msgs"},next:{title:"lasr_voice",permalink:"/docs/packages/lasr_voice"}},s={},p=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Usage",id:"usage",level:2},{value:"Example",id:"example",level:2},{value:"Technical Overview",id:"technical-overview",level:2},{value:"ROS Definitions",id:"ros-definitions",level:2},{value:"Launch Files",id:"launch-files",level:3},{value:"<code>service</code>",id:"service",level:4},{value:"<code>camera</code>",id:"camera",level:4},{value:"<code>demo</code>",id:"demo",level:4},{value:"Messages",id:"messages",level:3},{value:"Services",id:"services",level:3},{value:"Actions",id:"actions",level:3}],c={toc:p},u="wrapper";function m(e){let{components:t,...a}=e;return(0,r.kt)(u,(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"lasr_vision_yolov8"},"lasr_vision_yolov8"),(0,r.kt)("p",null,"YOLOv8 object detection service"),(0,r.kt)("p",null,"This package is maintained by:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"mailto:me@insrt.uk"},"Paul Makles"))),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("p",null,"This package depends on the following ROS packages:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"catkin (buildtool)"),(0,r.kt)("li",{parentName:"ul"},"catkin_virtualenv (build)"),(0,r.kt)("li",{parentName:"ul"},"lasr_vision_msgs")),(0,r.kt)("p",null,"This packages requires Python 3.10 to be present."),(0,r.kt)("p",null,"This package has 52 Python dependencies:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pypi.org/project/ultralytics"},"ultralytics"),"==8.0.168"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pypi.org/project/dill"},"dill"),"==0.3.7"),(0,r.kt)("li",{parentName:"ul"},".. and 50 sub dependencies")),(0,r.kt)("h2",{id:"usage"},"Usage"),(0,r.kt)("p",null,"This package provides the ",(0,r.kt)("inlineCode",{parentName:"p"},"/yolov8/detect")," service which uses the ",(0,r.kt)("inlineCode",{parentName:"p"},"YoloDetection")," service definition from ",(0,r.kt)("inlineCode",{parentName:"p"},"lasr_vision_msgs"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from lasr_vision_msgs.srv import YoloDetection, YoloDetectionRequest\n\n# create service proxy\ndetect_service = rospy.ServiceProxy('/yolov8/detect', YoloDetection)\n\n# create request\nrequest = YoloDetectionRequest()\nrequest.image_raw = image # sensor_msgs/Image\nrequest.dataset = \"yolov8n.pt\" # YOLOv8 model, auto-downloads\nrequest.confidence = 0.0 # minimum confidence to include in results\nrequest.nms = 0.0 # non maximal supression\n\n# send request\nresponse = detect_service(request)\n# .. use request.detections\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"You can find ",(0,r.kt)("a",{parentName:"p",href:"https://docs.ultralytics.com/models/yolov8/#supported-tasks"},"all available (on-demand) models here"),"."),(0,r.kt)("p",{parentName:"blockquote"},"Place additional models into the ",(0,r.kt)("inlineCode",{parentName:"p"},"models")," folder.")),(0,r.kt)("p",null,"To start the service:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# use the launch file:\nroslaunch lasr_vision_yolov8 service.launch\n# .. optionally configure debug / preload:\nroslaunch lasr_vision_yolov8 service.launch debug:=true preload:=["yolov8n-seg.pt"]\n')),(0,r.kt)("h2",{id:"example"},"Example"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Find a video to test on, or otherwise acquire an image topic."),(0,r.kt)("p",{parentName:"li"},"My test video is ",(0,r.kt)("inlineCode",{parentName:"p"},"https://www.youtube.com/watch?v=ng8Wivt52K0"),", ",(0,r.kt)("a",{parentName:"p",href:"https://co.wukko.me/"},"download it using Cobalt")," then place it in a directory such as ",(0,r.kt)("inlineCode",{parentName:"p"},"~/v.mp4"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Then launch the demo:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"roslaunch lasr_vision_yolov8 demo.launch file:=$HOME/v.mp4\n\n# .. you can also try other models:\nroslaunch lasr_vision_yolov8 demo.launch model:=yolov8n.pt file:=$HOME/v.mp4\n")))),(0,r.kt)("h2",{id:"technical-overview"},"Technical Overview"),(0,r.kt)("p",null,"There are currently two components to this package:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},'The YOLO "server" which runs inference and uses IPC (Python ',(0,r.kt)("inlineCode",{parentName:"li"},"multiprocessing"),") to communicate with a rospy node."),(0,r.kt)("li",{parentName:"ul"},'The actual service node which uses IPC to communicate with the "server".')),(0,r.kt)("p",null,"This is a temporary solution to workaround the minimum Python requirements for the ",(0,r.kt)("inlineCode",{parentName:"p"},"ultralytics")," Python package which wraps around YOLOv8 and provides an interface for running interface and collecting results."),(0,r.kt)("p",null,"The actual YOLO detection routine works as follows:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Decode the image using Pillow and numpy"),(0,r.kt)("p",{parentName:"li"},"Pillow is used to decode the image and numpy is used to flip BGR to RGB if necessary."),(0,r.kt)("p",{parentName:"li"},"The following encodings are currently supported:"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"bgr8"),(0,r.kt)("li",{parentName:"ul"},"8UC3"),(0,r.kt)("li",{parentName:"ul"},"rgb8")),(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},"[!NOTE]",(0,r.kt)("br",{parentName:"p"}),"\n","This could be turned into a utility library."))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Load the appropriate YOLO model"),(0,r.kt)("p",{parentName:"li"},"Models are loaded from the ",(0,r.kt)("inlineCode",{parentName:"p"},"models")," folder. Standard v8 models are loaded on-demand and saved to the directory as well."),(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},"[!IMPORTANT]",(0,r.kt)("br",{parentName:"p"}),"\n","If you would like to train your own model, ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/insertish/yolov8_training_workspace"},"a full guide is available here"),".")),(0,r.kt)("p",{parentName:"li"},"One or more models may be loaded at the same time, they are stored in an in-memory cache."),(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},"[!WARNING]",(0,r.kt)("br",{parentName:"p"}),"\n","Take care to keep track of how many different models you are loading."))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Run inference"),(0,r.kt)("p",{parentName:"li"},"This is entirely handled by the Python package.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Construct response"),(0,r.kt)("p",{parentName:"li"},"Tensors containing masks are converted to Python arrays to be sent back to the client requesting the detection."),(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},"[!IMPORTANT]",(0,r.kt)("br",{parentName:"p"}),"\n","Tensors may not be stored in CPU memory, so they may have to be moved first using ",(0,r.kt)("inlineCode",{parentName:"p"},".cpu()"),".")))),(0,r.kt)("h2",{id:"ros-definitions"},"ROS Definitions"),(0,r.kt)("h3",{id:"launch-files"},"Launch Files"),(0,r.kt)("h4",{id:"service"},(0,r.kt)("inlineCode",{parentName:"h4"},"service")),(0,r.kt)("p",null,"Start the YOLOv8 service"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# YOLOv8 service\nroslaunch lasr_vision_yolov8 service.launch \n\n# Preload models and enable debug topic\nroslaunch lasr_vision_yolov8 service.launch debug:=true preload:=['yolov8n.pt','yolov8n-seg.pt']\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Argument"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Default"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"debug"),(0,r.kt)("td",{parentName:"tr",align:"center"},"false"),(0,r.kt)("td",{parentName:"tr",align:null},"Whether to publish plotted images to /yolov8/debug")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"preload"),(0,r.kt)("td",{parentName:"tr",align:"center"},"[]"),(0,r.kt)("td",{parentName:"tr",align:null},"Array of models to preload when starting the service")))),(0,r.kt)("h4",{id:"camera"},(0,r.kt)("inlineCode",{parentName:"h4"},"camera")),(0,r.kt)("p",null,"Run a YOLOv8 model using the camera"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# Run the demo\nroslaunch lasr_vision_yolov8 camera.launch \n\n# Run the demo with a different model\nroslaunch lasr_vision_yolov8 camera.launch model:=yolov8n.pt\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Argument"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Default"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"model"),(0,r.kt)("td",{parentName:"tr",align:"center"},"yolov8n-seg.pt"),(0,r.kt)("td",{parentName:"tr",align:null},"Model to use for the demo")))),(0,r.kt)("h4",{id:"demo"},(0,r.kt)("inlineCode",{parentName:"h4"},"demo")),(0,r.kt)("p",null,"Run a YOLOv8 model on a video file"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# Run the demo\nroslaunch lasr_vision_yolov8 demo.launch file:=$HOME/video.mp4\n\n# Run the demo with a different model\nroslaunch lasr_vision_yolov8 demo.launch model:=yolov8n.pt file:=$HOME/video.mp4\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"Argument"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Default"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"model"),(0,r.kt)("td",{parentName:"tr",align:"center"},"yolov8n-seg.pt"),(0,r.kt)("td",{parentName:"tr",align:null},"Model to use for the demo")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"file"),(0,r.kt)("td",{parentName:"tr",align:"center"}),(0,r.kt)("td",{parentName:"tr",align:null},"Video file to run inference on")))),(0,r.kt)("h3",{id:"messages"},"Messages"),(0,r.kt)("p",null,"This package has no messages."),(0,r.kt)("h3",{id:"services"},"Services"),(0,r.kt)("p",null,"This package has no services."),(0,r.kt)("h3",{id:"actions"},"Actions"),(0,r.kt)("p",null,"This package has no actions."))}m.isMDXComponent=!0}}]);